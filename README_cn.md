# ğŸ”¥ Open-dLLM: å¼€æºæ‰©æ•£å¼å¤§è¯­è¨€æ¨¡å‹

ğŸ‘‰ TL;DR: **Open-dLLM** æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¼€æ”¾çš„æ‰©æ•£å¼å¤§è¯­è¨€æ¨¡å‹å‘å¸ƒ â€”â€”
æˆ‘ä»¬å¼€æºäº† **é¢„è®­ç»ƒã€è¯„æµ‹ã€æ¨ç†ä»¥åŠæ¨¡å‹æƒé‡**ã€‚

æœ¬ä»“åº“ä»‹ç»äº† **Open-dCoder**ï¼Œå®ƒæ˜¯ Open-dLLM çš„ **ä»£ç ç”Ÿæˆç‰ˆæœ¬**ã€‚

<p align="center">
  <a href="https://github.com/pengzhangzhi/Open-dLLM">
    <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" width="40" alt="GitHub"/>
  </a>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://oval-shell-31c.notion.site/Open-Diffusion-Large-Language-Model-25e03bf6136480b7a4ebe3d53be9f68a?pvs=74">
    <img src="https://upload.wikimedia.org/wikipedia/commons/e/e9/Notion-logo.svg" width="40" alt="Notion"/>
  </a>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://huggingface.co/fredzzp/open-dcoder-0.5B">
    <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="40" alt="Hugging Face"/>
  </a>
</p>

<p align="center">
  <b>ğŸ’» ä»£ç </b> &nbsp; | &nbsp; <b>ğŸ“– åšå®¢</b> &nbsp; | &nbsp; <b>ğŸ¤— æ¨¡å‹</b>
</p>

---

## ğŸ¥ æ¼”ç¤º

<p align="center">
  <img src="https://github.com/pengzhangzhi/dLLM-training/blob/main/assets/quick-sort-demo.gif" 
       alt="Quick Sort Demo" width="600"/>
</p>

<p align="center"><i>ä½¿ç”¨ Open-dCoder (0.5B) ç”Ÿæˆå¿«é€Ÿæ’åºç®—æ³•</i></p>

<p align="center">
  <a href="https://youtu.be/d8WrmvUhO9g">
    <img src="https://img.shields.io/badge/YouTube-è§†é¢‘-red?logo=youtube" alt="YouTube link"/>
  </a>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://www.bilibili.com/video/BV1ZveSz3E1J/">
    <img src="https://img.shields.io/badge/Bilibili-è§†é¢‘-blue?logo=bilibili" alt="Bilibili link"/>
  </a>
</p>

---

## âœ¨ äº®ç‚¹

* ğŸ‹ï¸ **å®Œæ•´é¢„è®­ç»ƒæµç¨‹ + å¼€æºæ•°æ®é›†**
* âš¡ **æ¨ç†è„šæœ¬** â€”â€” ç®€å•è¿è¡Œé‡‡æ ·å’Œç”Ÿæˆ
* ğŸ“Š **è¯„æµ‹å¥—ä»¶** â€”â€” HumanEvalã€MBPPã€ä»£ç ï¼ˆæ”¯æŒ lm-eval-harness + è‡ªå®šä¹‰æŒ‡æ ‡ï¼‰
* ğŸ“¦ **æ¨¡å‹æƒé‡**ï¼ˆå·²ä¸Šä¼ åˆ° Hugging Faceï¼‰
* ğŸ¤ **é€æ˜é…ç½®**ï¼Œå¯å®Œå…¨å¤ç°

---

## ä¸ºä»€ä¹ˆé€‰æ‹© Open-dLLMï¼Ÿ

ç›®å‰å¤§å¤šæ•°æ‰©æ•£å¼ LLM ä»“åº“ï¼ˆä¾‹å¦‚ LLaDAã€Dreamï¼‰åªå¼€æºäº† **æ¨ç†ä»£ç å’Œæƒé‡**ï¼Œé™åˆ¶äº†å¤ç°æ€§ã€‚
**Open-dLLM** æ˜¯ç¬¬ä¸€ä¸ªå¼€æº **å…¨æ ˆ** çš„æ‰©æ•£å¼ LLMï¼š

ğŸ‘‰ ä» **åŸå§‹æ•°æ® â†’ è®­ç»ƒ â†’ æƒé‡ â†’ è¯„æµ‹ â†’ æ¨ç†**ï¼Œå…¨æµç¨‹ä¸€ä¸ªä»“åº“æå®šã€‚

---

## ğŸ” æ‰©æ•£å¼ LLM å¼€æ”¾ç¨‹åº¦å¯¹æ¯”

| é¡¹ç›®                                                                                 |  æ•°æ® | è®­ç»ƒä»£ç  |  æ¨ç† |   è¯„æµ‹  |     æƒé‡    |
| ---------------------------------------------------------------------------------- | :-: | :--: | :-: | :---: | :-------: |
| **Open-dLLM / Open-dCoder (ours)**                                                 |  âœ…  |   âœ…  |  âœ…  |   âœ…   |     âœ…     |
| [LLaDA](https://github.com/ML-GSAI/LLaDA)                                          |  âŒ  |   âŒ  |  âœ…  | âš ï¸ éƒ¨åˆ† |     âœ…     |
| [Dream](https://github.com/HKUNLP/Dream)                                           |  âŒ  |   âŒ  |  âœ…  | âš ï¸ éƒ¨åˆ† |     âœ…     |
| [Gemini-Diffusion](https://deepmind.google/models/gemini-diffusion/)               |  âŒ  |   âŒ  |  âŒ  |   âŒ   | âŒ (ä»… API) |
| [Seed Diffusion](https://seed.bytedance.com/seed_diffusion)                        |  âŒ  |   âŒ  |  âŒ  |   âŒ   | âŒ (ä»… API) |
| [Mercury](https://www.inceptionlabs.ai/introducing-mercury-our-general-chat-model) |  âŒ  |   âŒ  |  âŒ  |   âŒ   | âŒ (ä»… API) |

âœ… = å®Œå…¨å¼€æº Â· âŒ = æœªæä¾› Â· âš ï¸ = éƒ¨åˆ†/æœ‰é™

---

## âš™ï¸ å®‰è£…

æˆ‘ä»¬æ¨èä½¿ç”¨ `micromamba` ç®¡ç†ç¯å¢ƒï¼ˆä¹Ÿå¯æ”¹ç”¨ `conda`ï¼‰ï¼š

```bash
micromamba install -c nvidia/label/cuda-12.3.0 cuda-toolkit -y
pip install ninja

# å®‰è£…æœ€æ–° torch (cu121)
pip install torch==2.5.0 --index-url https://download.pytorch.org/whl/cu121

pip install "flash-attn==2.7.4.post1" \
  --extra-index-url https://github.com/Dao-AILab/flash-attention/releases/download

pip install --upgrade --no-cache-dir \
  tensordict torchdata byte-flux triton>=3.1.0 \
  transformers==4.54.1 accelerate datasets peft hf-transfer \
  codetiming hydra-core pandas pyarrow>=15.0.0 pylatexenc \
  wandb ninja liger-kernel==0.5.8 \
  pytest yapf py-spy pyext pre-commit ruff packaging

pip install -e .
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šé‡‡æ ·

```python
from transformers import AutoTokenizer
from veomni.models.transformers.qwen2.modeling_qwen2 import Qwen2ForCausalLM
from veomni.models.transformers.qwen2.generation_utils import MDMGenerationConfig
import torch

model_id = "fredzzp/open-dcoder-0.5B"
device = "cuda" if torch.cuda.is_available() else "cpu"

# åŠ è½½ tokenizer + æ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
model = Qwen2ForCausalLM.from_pretrained(
    model_id, torch_dtype=torch.bfloat16, trust_remote_code=True
).to(device).eval()

# è¾“å…¥æç¤º
prompt = "ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ã€‚"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)

# ç”Ÿæˆé…ç½®
gen_cfg = MDMGenerationConfig(max_new_tokens=128, steps=200, temperature=0.7)

with torch.no_grad():
    outputs = model.diffusion_generate(inputs=input_ids, generation_config=gen_cfg)

print(tokenizer.decode(outputs.sequences[0], skip_special_tokens=True))
```

ğŸ‘‰ æ›´å¤šæ—¥å¿—è®°å½•ä¸æ–‡ä»¶è¾“å‡ºï¼š

```bash
python sample.py
```

---

## ğŸ“Š åŸºå‡†æµ‹è¯•

æˆ‘ä»¬å¼€æºäº†å®Œæ•´çš„ **è¯„æµ‹å¥—ä»¶**ï¼Œè¦†ç›– **æ ‡å‡†ä»£ç ç”Ÿæˆä»»åŠ¡** å’Œ **ä»£ç å¡«å……ä»»åŠ¡**ï¼š

* HumanEval / HumanEval+
* MBPP / MBPP+
* HumanEval-Infill
* SantaCoder-FIM

ç»“æœè¡¨æ ¼ä¸ README ä¸­ä¸€è‡´ï¼Œè¿™é‡Œä¸å†é‡å¤ã€‚

---

## ğŸ‹ï¸ é¢„è®­ç»ƒ

* **æ•°æ®**: å¼€æºé«˜è´¨é‡ä»£ç è¯­æ–™ [**FineCode**](https://huggingface.co/datasets/fredzzp/fine_code)
* **åˆå§‹åŒ–**: åŸºäº **Qwen2.5-Coder** ç»§ç»­é¢„è®­ç»ƒï¼Œä»è‡ªå›å½’ â†’ æ‰©æ•£
* **ç›®æ ‡å‡½æ•°**: Masked Diffusion Model (MDM)ï¼Œmask æ¯”ä¾‹å‡åŒ€é‡‡æ · `[0,1]`

---

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®å»ºç«‹åœ¨ä»¥ä¸‹å·¥ä½œä¹‹ä¸Šï¼š

* **æ¡†æ¶ä¸å·¥å…·**: [VeOmni](https://github.com/ByteDance-Seed/VeOmni), [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness)
* **å¼€æº dLLM**: [LLaDA](https://github.com/ML-GSAI/LLaDA), [Dream](https://github.com/HKUNLP/Dream)
* **å…ˆé”‹æ¢ç´¢**: [Gemini-Diffusion](https://deepmind.google/models/gemini-diffusion/), [Seed Diffusion](https://seed.bytedance.com/seed_diffusion), [Mercury](https://www.inceptionlabs.ai/introducing-mercury-our-general-chat-model)
* **åŸºç¡€ç ”ç©¶**: [MD4](https://proceedings.neurips.cc/paper_files/paper/2024/hash/bad233b9849f019aead5e5cc60cef70f-Abstract-Conference.html), [MDLM](https://arxiv.org/abs/2406.07524), [DPLM](https://github.com/bytedance/dplm)

æˆ‘ä»¬å¸Œæœ› **Open-dLLM** èƒ½å›é¦ˆç¤¾åŒºï¼Œæ¨åŠ¨æ‰©æ•£å¼å¤§è¯­è¨€æ¨¡å‹ç ”ç©¶ã€‚

---

## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨ **Open-dLLM** æˆ– **Open-dCoder**ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{opendllm2025,
  title        = {Open-dLLM: Open Diffusion Large Language Models},
  author       = {Fred Zhangzhi Peng, Shuibai Zhang, Alex Tong, and contributors},
  year         = {2025},
  howpublished = {\url{https://github.com/pengzhangzhi/Open-dLLM}},
  note         = {Blog: \url{https://oval-shell-31c.notion.site/Open-Diffusion-Large-Language-Model-25e03bf6136480b7a4ebe3d53be9f68a?pvs=74}, 
                  Model: \url{https://huggingface.co/fredzzp/open-dcoder-0.5B}}
}
```
